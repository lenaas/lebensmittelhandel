{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2767d4c-a6a3-4a67-9c4f-625301258457",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6244b7b0-1a14-4c4d-96a3-8bf422451447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import plotly.offline as po\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49814d63-e2d2-42f4-ad68-89ff1b8cd070",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def autocomplete_product(stump):\n",
    "    \"\"\" Autocomplete (Case Insensitive) Product Name and provide ID \"\"\"\n",
    "    # for each product\n",
    "    for x in raw.product_name.unique():\n",
    "        # if it contains provided stump\n",
    "        if x.lower().__contains__(stump.lower()):\n",
    "            # print name and id\n",
    "            print(f\"{x} - {name_to_id[x]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25a8f285-b148-4c67-b222-37b05a06fa13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_graph(df, name, plot=False, offline=True, notebook=False, nf=0.05):\n",
    "    \"\"\"\n",
    "    Create Graph of products. Node size ~ totals sales. Edge strength ~ shared sales adjusted for total sales.\n",
    "    \n",
    "    :df -> Dataframe to generate edges from\n",
    "    :name -> file suffix for html page\n",
    "    :offline -> create html page with plot and display as new tab\n",
    "    :notebook -> display in notebook\n",
    "    :nf -> normalizing factor for path strenght. Smaller values => thicker edges\n",
    "    \"\"\"\n",
    "    # create edgelist\n",
    "    G = nx.from_pandas_edgelist(df, source=\"product_x\", target=\"product_y\", edge_attr=True)\n",
    "    # position nodes using Fruchterman-Reingold force-directed algorithm\n",
    "    pos_ = nx.spring_layout(G)\n",
    "    \n",
    "    # generate plotly trace for every edge\n",
    "    edge_trace = []\n",
    "    for edge in G.edges():\n",
    "\n",
    "        if G.edges()[edge]['weight'] > 0:\n",
    "            prod_1 = edge[0]\n",
    "            prod_2 = edge[1]\n",
    "\n",
    "            x0, y0 = pos_[prod_1]\n",
    "            x1, y1 = pos_[prod_2]\n",
    "            # generate hovertext (only displays on starting point. Bug in Plotly https://community.plotly.com/t/plotly-hover-event-not-getting-triggered-for-al-data-points/387)\n",
    "            text   = str(id_to_name[prod_2]) + '--' + str(id_to_name[prod_1]) + ': ' + str(G.edges()[edge]['weight'])\n",
    "            # calculate adjusted width\n",
    "            width = G.edges()[edge]['weight']/(nf*prod_count[prod_1]+nf*prod_count[prod_2])\n",
    "            # generate trace\n",
    "            trace = go.Scatter(x = [x0, x1, None], y = [y0, y1, None],\n",
    "                               line      = dict(width=width, color='green'),\n",
    "                               hoverinfo = 'text',\n",
    "                               text      = ([text]),\n",
    "                               mode      = 'lines')\n",
    "            # append to edge_trace list\n",
    "            edge_trace.append(trace)\n",
    "            \n",
    "    # create empty node trace\n",
    "    node_trace = go.Scatter(x = [], y = [],\n",
    "                            text      = [],\n",
    "                            textposition = \"top center\",\n",
    "                            textfont_size = 10,\n",
    "                            mode      = 'markers+text',\n",
    "                            hoverinfo = 'none',\n",
    "                            marker    = dict(color=[], size=[], line=None))\n",
    "    # add every node to node_trace \n",
    "    for node in G.nodes():\n",
    "        x, y = pos_[node]\n",
    "        node_trace['x'] += tuple([x])\n",
    "        node_trace['y'] += tuple([y])\n",
    "        node_trace['marker']['color'] += tuple(['cornflowerblue'])\n",
    "        node_trace['marker']['size'] += tuple([np.log(prod_count[node])])\n",
    "        node_trace['text'] += tuple([id_to_name[node]])\n",
    "    # create layout\n",
    "    layout = go.Layout(\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        plot_bgcolor='rgba(0,0,0,0)'\n",
    "    )\n",
    "    # create figure\n",
    "    fig = go.Figure(layout = layout)\n",
    "    \n",
    "    # add edge traces\n",
    "    for trace in edge_trace:\n",
    "        fig.add_trace(trace)\n",
    "    \n",
    "    # add node traces\n",
    "    fig.add_trace(node_trace)\n",
    "    \n",
    "    # cleanup layout\n",
    "    fig.update_layout(showlegend = False)\n",
    "    fig.update_xaxes(showticklabels = False)\n",
    "    fig.update_yaxes(showticklabels = False)\n",
    "    # display in specified way(s)\n",
    "    if notebook:\n",
    "        fig.show()\n",
    "    if offline:\n",
    "        po.plot(fig, filename=f'networks/network_{name}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd535efc-fbd1-4838-87c1-e863f108967b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cl_department(department):\n",
    "    \"\"\"\n",
    "    Create Cooccurrency List for Department\n",
    "    \n",
    "    :department -> department for which to filter for\n",
    "    \"\"\"\n",
    "    # filter and copy\n",
    "    df = raw[raw.department == department][[\"order_id\", \"product_id\"]].copy()\n",
    "    # rename columns\n",
    "    df.rename(columns={\"order_id\":\"order\", \"product_id\":\"product\"}, inplace=True)\n",
    "    # create cooccurrency list\n",
    "    # steps:\n",
    "    # merge to self and drop rows with reflexive relationship\n",
    "    # group by both products and count occurences\n",
    "    # rename columns\n",
    "    # filter duplicate rows\n",
    "    # sort and reset index\n",
    "    df_coocc = df.merge(df, on=['order']).query('product_x != product_y')\\\n",
    "        .groupby(['product_x','product_y'], as_index=False).count()\\\n",
    "        .rename(columns={'order':'weight'})\\\n",
    "        .query('product_x < product_y')\\\n",
    "        .sort_values(by=\"weight\", ignore_index=True)\n",
    "    return df_coocc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5be2d5-ffc7-4216-9383-f63b44bbf44f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def graph_product(product_id, top_n=25, filter_dict=None, offline=True, notebook=False, nf=0.05):\n",
    "    \"\"\"\n",
    "    Draw Cooccurrency Graph for specified Product\n",
    "    \n",
    "    :product_id -> center of graph\n",
    "    :filter_dict -> limit by condition passsed as dict. To filter to county Alpine,\n",
    "    pass filter_dict = {\"county\": \"Alpine\"}\n",
    "    :top_n -> number of relationships to include (by absolute number of cooccurrencies)\n",
    "    :offline -> create html page with plot and display as new tab\n",
    "    :notebook -> display in notebook\n",
    "    :nf -> normalizing factor for path strenght. Smaller values => thicker edges\n",
    "    \"\"\"\n",
    "    # create copy\n",
    "    df = raw.copy()\n",
    "    # filter rows that dont satisfy conditions if filters are passed\n",
    "    if filter_dict:\n",
    "        for key in filter_dict.keys():\n",
    "            df = df[df[key] == filter_dict[key]]\n",
    "    df = df[[\"order_id\", \"product_id\"]]\n",
    "    # rename columns\n",
    "    df.rename(columns={\"order_id\":\"order\", \"product_id\":\"product\"}, inplace=True)\n",
    "    # create cooccurrency list\n",
    "    # steps:\n",
    "    # merge to self and filter to relevant rows\n",
    "    # drop reflexive relationships\n",
    "    # group by both products and count occurences\n",
    "    # rename columns\n",
    "    # filter duplicate rows\n",
    "    # sort and reset index\n",
    "    df_coocc = df.merge(df, on=['order']).query(f'product_x == {product_id} | product_y == {product_id}')\\\n",
    "            .query('product_x != product_y')\\\n",
    "            .groupby(['product_x','product_y'], as_index=False).count()\\\n",
    "            .rename(columns={'order':'weight'})\\\n",
    "            .query('product_x < product_y')\\\n",
    "            .sort_values(by=\"weight\", ignore_index=True)\n",
    "    # draw graph\n",
    "    create_graph(df_coocc.tail(top_n), product_id, offline=offline, notebook=notebook, nf=nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "424a69fc-0835-448d-8cc1-9731946ea4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw data\n",
    "raw = pd.read_parquet(\"shoppingcarts.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c75bccd-2525-4b0e-a462-38672afcaff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lookup tables for id to name and vice versa \n",
    "# for product\n",
    "id_to_name = dict(zip(raw.product_id.unique(), raw.product_name.unique()))\n",
    "name_to_id = dict(zip(raw.product_name.unique(), raw.product_id.unique()))\n",
    "# for aisle\n",
    "aisle_id_to_name = dict(zip(raw.aisle_id.unique(), raw.aisle.unique()))\n",
    "aisle_name_to_id = dict(zip(raw.aisle.unique(), raw.aisle_id.unique()))\n",
    "# for department\n",
    "dep_id_to_name = dict(zip(raw.department_id.unique(), raw.department.unique()))\n",
    "dep_name_to_id = dict(zip(raw.department.unique(), raw.department_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7de91f-1d2c-46b1-97c5-0262baf4de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of orders per product, aisle, department and county\n",
    "prod_count = raw.groupby(\"product_id\")[\"order_id\"].count()\n",
    "aisle_count = raw.groupby(\"aisle_id\")[\"order_id\"].count()\n",
    "dep_count = raw.groupby(\"department_id\")[\"order_id\"].count()\n",
    "county_count = raw.groupby(\"county\")[\"order_id\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04db692b-c1d9-4808-9a48-1cdeedf9c465",
   "metadata": {},
   "source": [
    "# Live Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f6fef14-52c0-4063-b0e7-9ee76ebf056f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Chili con Carne with Beans - 35621\n",
      "Original W/Beans Chili Con Carne - 21307\n",
      "Chunky W/Beans Chili Con Carne - 47726\n",
      "Chili Con Carne No Bean - 42158\n",
      "Original Chili Con Carne With Beans - 25075\n",
      "Chili Con Carne With Beans - 24989\n",
      "Chili Con Carne - 14132\n",
      "Hot Chili Con Carne With Beans - 18866\n"
     ]
    }
   ],
   "source": [
    "# Use this to find Product-Ids\n",
    "# shows all products containing stub. Case insensitive\n",
    "autocomplete_product(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96cfd7dd-3699-40c3-9d5a-0e22725a311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create product graph\n",
    "# offline -> create html page with plot and display as new tab\n",
    "# notebook -> display in notebook\n",
    "graph_product(product_id=, top_n=50, filter_dict=None, nf=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a7666-c237-4778-9cd6-bfc3ebd83e62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
